# Source Citation Implementation

## Overview
Implemented mandatory source citations for all AI-generated responses in the OLAMA platform. The system now provides transparent references for both RAG-based (document-sourced) and non-RAG (model-generated) responses.

## Features Implemented

### 1. **RAG Responses with Page Numbers**
- Automatically extracts and displays page numbers from source documents
- Shows relevance scores for each citation
- Displays document name and excerpt from the source
- Citations are appended to the response text with clear formatting

### 2. **Non-RAG Response Disclaimers**
- Adds a disclaimer note for responses generated without document context
- Includes the model name used for generation
- Reminds users to verify important information

### 3. **Structured Source Citations**
Each citation includes:
- **Source Type**: `document` (for RAG) or `model` (for AI generation)
- **Source Name**: Document/index name or model name
- **Page Number**: Extracted from document metadata (PDFs, DOCX, etc.)
- **Relevance Score**: Hybrid search relevance score (0.0 to 1.0)
- **Excerpt**: Brief preview of the source content

## Technical Changes

### Backend Changes

#### 1. **schemas/response_schemas.py**
- Added `SourceCitation` model with fields:
  - `source_type`: Type of source (document/model)
  - `source_name`: Name of the document or model
  - `page_number`: Page reference for documents
  - `relevance_score`: RAG relevance score
  - `excerpt`: Brief text excerpt
- Updated `GenerateResponse` to include `sources` field

#### 2. **routes/generate.py**
- Modified `fetch_relevant_context()` to return tuple: `(context_string, sources_list)`
- Extracts page numbers from metadata (`page` or `slide` fields)
- Creates `SourceCitation` objects for each retrieved document chunk
- Appends formatted citations to the generated response
- Adds model citation for all responses
- Adds disclaimer for non-RAG responses

#### 3. **schemas/__init__.py**
- Exported `SourceCitation` model

### Frontend Changes

#### 1. **frontend/src/types/api.ts**
- Added `SourceCitation` interface matching backend schema
- Updated `GenerateResponse` to include `sources?: SourceCitation[]`

#### 2. **frontend/src/types/session.ts**
- Added import for `SourceCitation` type
- Updated `ChatMessage` and `StoredChatMessage` to include:
  - `model?: string`
  - `sources?: SourceCitation[]`

#### 3. **frontend/src/hooks/useGeneration.ts**
- Updated to pass `sources` from API response to message object

#### 4. **frontend/src/components/ChatInterface.tsx**
- Added source citation display section for assistant messages
- Shows document sources with page numbers
- Displays relevance scores as percentages
- Includes model generation notice
- Styled with gray background boxes and teal accents for page numbers

## Usage Examples

### RAG Response Example:
```
Response: "Based on the provided context, quantum computing uses qubits..."

---
**Sources:**

1. quantum_physics_guide, Page 42 (relevance: 95%)
2. advanced_computing, Page 17 (relevance: 87%)

*Response generated by AI model: llama3.2:1b*
```

### Non-RAG Response Example:
```
Response: "Quantum computing is a revolutionary computing paradigm..."

---
*Note: This response was generated by the AI model 'llama3.2:1b'. 
Please verify important information from authoritative sources.*
```

### Frontend Display:
- Document sources appear in gray boxes with:
  - Document name in bold
  - Page number in teal color
  - Relevance percentage in small gray text
- Model reference shown in italics below sources

## Data Flow

1. **User Query** → Backend receives request with optional indices
2. **RAG Search** (if indices provided) → Retrieves relevant chunks with metadata
3. **Source Extraction** → Extracts page numbers, scores, excerpts
4. **Response Generation** → LLM generates response using augmented context
5. **Citation Formatting** → Appends sources section to response text
6. **API Response** → Returns response + sources array
7. **Frontend Display** → Renders response with formatted source citations

## Benefits

1. **Transparency**: Users know exactly where information comes from
2. **Traceability**: Easy to verify information by checking page numbers
3. **Trust**: Clear distinction between document-based and AI-generated content
4. **Compliance**: Meets requirements for source attribution
5. **User Experience**: Clean, readable citation format

## File Locations

### Backend Files Modified:
- `schemas/response_schemas.py`
- `schemas/__init__.py`
- `routes/generate.py`

### Frontend Files Modified:
- `frontend/src/types/api.ts`
- `frontend/src/types/session.ts`
- `frontend/src/hooks/useGeneration.ts`
- `frontend/src/components/ChatInterface.tsx`

## Future Enhancements

Potential improvements:
1. Click-to-view source document preview
2. Highlight exact text in source document
3. Export citations in standard formats (APA, MLA, Chicago)
4. Citation filtering and sorting options
5. Source credibility scoring
6. Multi-language citation support

## Testing Recommendations

1. Test with PDF documents with page numbers
2. Test with PowerPoint presentations (slide numbers)
3. Test with DOCX files
4. Test non-RAG responses (without indices)
5. Test hybrid responses (RAG + model knowledge)
6. Verify citation formatting in frontend
7. Check source persistence across sessions

## Notes

- Page numbers are extracted from document metadata during ingestion
- Documents without page metadata will show citations without page numbers
- Relevance scores are from hybrid search (semantic + keyword)
- All responses now include at least a model citation
- Citations are part of the response text for copy-paste convenience
