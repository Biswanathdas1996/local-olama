# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=300

# Application Configuration
APP_NAME="Local LLM Platform"
APP_VERSION=1.0.0
DEBUG=False
LOG_LEVEL=INFO

# Server Configuration
HOST=0.0.0.0
PORT=8000

# Performance Settings
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=300
MAX_PROMPT_SIZE_MB=10

# Document Ingestion & RAG Settings
EMBEDDING_MODEL=nomic-embed-text-v1.5
CHUNK_SIZE=512
CHUNK_OVERLAP=100
VECTOR_STORE_PATH=./data/vector_store
KEYWORD_INDEX_PATH=./data/keyword_index

# Hybrid Search Weights
SEMANTIC_WEIGHT=0.65
LEXICAL_WEIGHT=0.35

# Extraction Settings
USE_OCR=False
RESPECT_DOC_STRUCTURE=True
EXTRACT_KEYWORDS=True
KEYWORDS_PER_CHUNK=15

# Search Settings
DEFAULT_TOP_K=10
MIN_SEARCH_SCORE=0.3
