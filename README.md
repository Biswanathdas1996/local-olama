# LEANN - Local Enterprise AI & Neural Network Platform

Enterprise-grade on-premise RAG (Retrieval Augmented Generation) platform with advanced document processing and image understanding capabilities.

## ğŸš€ Key Features

### Document Processing
- **Structure-Aware Extraction** - Preserves document hierarchy using Docling
- **Multi-Format Support** - PDF, DOCX, PPTX, HTML, TXT
- **Smart Chunking** - Respects semantic boundaries and document structure
- **Metadata Preservation** - Maintains source context and references

### ğŸ–¼ï¸ Image Processing (NEW!)
- **OCR Text Extraction** - PaddleOCR for 80+ languages
- **Chart Parser** - Extracts data from graphs, plots, visualizations
- **Automatic Classification** - Identifies charts, tables, diagrams, photos
- **Description Generation** - Creates searchable natural language descriptions
- **Separate Image Pipeline** - Images processed independently from text

### Retrieval & Search
- **Hybrid Search** - Combines semantic (vector) + lexical (BM25) retrieval
- **State-of-the-Art Embeddings** - Local models (nomic-embed, BGE, MiniLM)
- **Keyword Extraction** - Automatic keyword indexing with KeyBERT
- **Advanced Filtering** - Search by content type, image type, metadata

### Enterprise Features
- **100% Local/On-Premise** - No cloud dependencies, complete data privacy
- **Offline Mode** - Full functionality without internet
- **Persistent Storage** - ChromaDB vector store with efficient indexing
- **Scalable Architecture** - Handles large document collections
- **GPU Acceleration** - Optional GPU support for faster processing

## ğŸ“‹ Prerequisites

- Python 3.8+
- 8GB+ RAM (16GB recommended)
- 10GB+ disk space
- Windows/Linux/macOS
- (Optional) NVIDIA GPU with CUDA for acceleration

## ğŸ”§ Installation

### 1. Clone Repository
```bash
git clone <repository-url>
cd Olama
```

### 2. Create Virtual Environment
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac
```

### 3. Install Core Dependencies
```bash
pip install -r requirements.txt
```

### 4. Install Image Processing (NEW!)
```bash
.\scripts\install-image-processing.ps1
```

### 5. Download Embedding Models
```bash
python scripts/download_embedding_models.py
```

### 6. Verify Installation
```bash
python scripts/test_image_processing.py
```

## ğŸš€ Quick Start

### Start Backend Server
```bash
python main.py
```

### Start Frontend (Optional)
```bash
cd frontend
npm install
npm run dev
```

### API Endpoints

**Ingest Document (with automatic image processing):**
```bash
POST http://localhost:8000/rag/ingest-doc
Content-Type: multipart/form-data

file: document.pdf
index_name: my_docs
```

**Search (across text and images):**
```bash
GET http://localhost:8000/rag/search?query=revenue chart&index_name=my_docs&top_k=10
```

**List Indices:**
```bash
GET http://localhost:8000/rag/indices
```

## ğŸ“š Documentation

### Core Documentation
- **[Image Processing Pipeline](IMAGE_PROCESSING_PIPELINE.md)** - Complete guide to image processing
- **[Quick Reference](IMAGE_PROCESSING_QUICK_REF.md)** - Quick command reference
- **[Implementation Summary](IMAGE_PROCESSING_IMPLEMENTATION.md)** - Technical implementation details
- **[Citation Guide](CITATION_QUICK_GUIDE.md)** - Source citation features
- **[Embedding Setup](EMBEDDING_SETUP.md)** - Embedding model configuration
- **[Offline Setup](OFFLINE_SETUP.md)** - Offline mode configuration

### Setup Guides
- **[Docling Setup](DOCLING_SETUP_COMPLETE.md)** - Document extraction setup
- **[Training Setup](SOURCE_CITATION_IMPLEMENTATION.md)** - Model training features

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Document Input                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                â”‚
   [Text Path]    [Image Path]
       â”‚                â”‚
       â†“                â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  Docling â”‚    â”‚  PaddleOCR   â”‚
 â”‚ Extractorâ”‚    â”‚  + Chart     â”‚
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â”‚   Parser     â”‚
      â”‚          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â†“                 â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ Semantic â”‚    â”‚ Description  â”‚
 â”‚ Chunker  â”‚    â”‚  Generator   â”‚
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                 â”‚
      â†“                 â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Embedding Generator    â”‚
 â”‚  (sentence-transformers) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Vector Database    â”‚
 â”‚    (ChromaDB)        â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚   Hybrid Search      â”‚
 â”‚ (Semantic + Lexical) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ–¼ï¸ Image Processing Flow

```
Image Input
    â”‚
    â”œâ”€â”€â–º OCR Engine (PaddleOCR)
    â”‚     â””â”€â”€â–º Extract text, labels, legends
    â”‚
    â”œâ”€â”€â–º Chart Parser
    â”‚     â””â”€â”€â–º Extract numerical data, chart type
    â”‚
    â”œâ”€â”€â–º Description Generator
    â”‚     â””â”€â”€â–º Create natural language description
    â”‚
    â”œâ”€â”€â–º Chunking
    â”‚     â””â”€â”€â–º Split into optimal chunks
    â”‚
    â””â”€â”€â–º Embedding + Storage
          â””â”€â”€â–º Store with image-specific metadata
```

## ğŸ“Š Supported Formats

### Documents
- PDF (with OCR support)
- DOCX (Microsoft Word)
- PPTX (PowerPoint)
- HTML
- TXT

### Images (Extracted from Documents)
- Charts & Graphs (bar, line, pie, scatter, etc.)
- Tables & Grids
- Diagrams & Flowcharts
- Screenshots
- Photos

### Image Processing Features
- Text extraction (80+ languages)
- Chart data parsing
- Automatic image classification
- Description generation
- Searchable metadata

## ğŸ” Search Capabilities

### Search Types
- **Hybrid** - Best results combining semantic + keyword matching
- **Semantic** - Pure vector similarity search
- **Lexical** - Traditional keyword-based search

### Filtering Options
```python
# Search only images
where={'content_type': 'image_description'}

# Search only charts
where={'image_type': 'chart'}

# Search specific document
where={'source_document': 'report.pdf'}

# Search specific page
where={'page_number': 5}
```

## âš™ï¸ Configuration

### Key Settings (`utils/config.py`)

```python
# Chunking
chunk_size: int = 1000
chunk_overlap: int = 150

# Embeddings
embedding_model: str = 'minilm'

# Search weights
semantic_weight: float = 0.7
lexical_weight: float = 0.3

# Image processing
enable_image_processing: bool = True
image_processor_gpu: bool = False
```

## ğŸ§ª Testing

### Run Full Test Suite
```bash
python scripts/test_image_processing.py
```

### Test Individual Components
```bash
# Test embedder
python -c "from core.embedder import get_embedder; print(get_embedder().get_model_info())"

# Test image processor
python -c "from core.image_processor import get_image_processor; print(get_image_processor().get_processor_info())"

# Test document extractor
python scripts/test_docling_extraction.py
```

## ğŸ“ˆ Performance

### Processing Speed (CPU)
- Text extraction: ~1 page/second
- Image OCR: ~2-3 seconds/image
- Embedding generation: ~100 chunks/second
- Search latency: ~50-100ms

### With GPU Acceleration
- Image OCR: ~0.5-1 second/image
- Embedding generation: ~500+ chunks/second

### Storage
- Text chunks: ~2KB/chunk
- Image descriptions: ~5KB/chunk
- Images on disk: ~50KB/image (metadata)

## ğŸ” Privacy & Security

- **100% Local Processing** - No data leaves your infrastructure
- **No External APIs** - All models run locally
- **Offline Capable** - Works without internet
- **Data Ownership** - Complete control over your data
- **Audit Trail** - Full logging and metadata tracking

## ğŸ“¦ Project Structure

```
Olama/
â”œâ”€â”€ core/                      # Core processing modules
â”‚   â”œâ”€â”€ doc_extractor.py      # Document extraction (Docling)
â”‚   â”œâ”€â”€ image_processor.py    # Image OCR & chart parsing (NEW!)
â”‚   â”œâ”€â”€ embedder.py           # Embedding generation
â”‚   â”œâ”€â”€ text_chunker.py       # Smart chunking
â”‚   â”œâ”€â”€ vector_store.py       # ChromaDB interface
â”‚   â”œâ”€â”€ hybrid_search.py      # Search engine
â”‚   â””â”€â”€ keyword_extractor.py  # Keyword extraction
â”œâ”€â”€ routes/                    # API routes
â”‚   â”œâ”€â”€ ingestion_routes.py   # Document ingestion (with images)
â”‚   â”œâ”€â”€ generate.py           # Text generation
â”‚   â””â”€â”€ training.py           # Model training
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ install-image-processing.ps1  # Image deps installer
â”‚   â”œâ”€â”€ test_image_processing.py      # Test suite
â”‚   â””â”€â”€ download_embedding_models.py  # Model downloader
â”œâ”€â”€ data/                      # Data storage
â”‚   â”œâ”€â”€ docling_output/       # Extracted documents + images
â”‚   â”œâ”€â”€ processed_images/     # OCR processed images
â”‚   â”œâ”€â”€ vector_store/         # Vector database
â”‚   â””â”€â”€ keyword_index/        # BM25 index
â”œâ”€â”€ models/                    # Model storage
â”‚   â”œâ”€â”€ embeddings/           # Embedding models
â”‚   â””â”€â”€ docling_models/       # Docling models
â””â”€â”€ frontend/                  # Web interface (optional)
```

## ğŸ› ï¸ Advanced Usage

### Custom Image Processing
```python
from core.image_processor import ImageProcessor

processor = ImageProcessor(
    use_gpu=True,
    lang='en',
    enable_chart_parsing=True
)

content = processor.process_image(
    'chart.png',
    metadata={'source': 'report.pdf', 'page': 5}
)
```

### Batch Document Processing
```python
from pathlib import Path
from core.doc_extractor import DocumentExtractor

extractor = DocumentExtractor()

for pdf in Path('documents/').glob('*.pdf'):
    doc = extractor.extract(open(pdf, 'rb'), pdf.name)
    print(f"Extracted {len(doc.images)} images from {pdf.name}")
```

### Custom Search Filters
```python
from core.hybrid_search import get_hybrid_search

search = get_hybrid_search()
results = search.search(
    collection_name='my_index',
    query_text='revenue chart',
    where={'image_type': 'chart', 'page_number': 5}
)
```

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:
- Additional chart types support
- More document formats
- Multi-modal embeddings (CLIP)
- Image similarity search
- Table structure extraction

## ğŸ“„ License

[Your License Here]

## ğŸ™ Acknowledgments

Built with:
- [Docling](https://github.com/DS4SD/docling) - Document extraction
- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) - OCR engine
- [sentence-transformers](https://github.com/UKPLab/sentence-transformers) - Embeddings
- [ChromaDB](https://github.com/chroma-core/chroma) - Vector database
- [FastAPI](https://github.com/tiangolo/fastapi) - API framework

## ğŸ“ Support

For issues and questions:
1. Check documentation in `/docs` folder
2. Review logs in `data/` directories
3. Run test suite: `python scripts/test_image_processing.py`
4. Check [GitHub Issues](your-repo-url/issues)

---

**Version:** 2.0.0 (with Image Processing)  
**Last Updated:** October 25, 2025  
**Status:** âœ… Production Ready
